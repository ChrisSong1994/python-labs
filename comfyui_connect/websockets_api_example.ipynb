{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa31c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ComfyUI URL: http://home.chrissong.top:3818\n"
     ]
    }
   ],
   "source": [
    "# 环境初始化\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# ComfyUI 服务地址\n",
    "COMFYUI_URL = os.getenv(\"COMFYUI_URL\")\n",
    "\n",
    "print(f\"Using ComfyUI URL: {COMFYUI_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example that uses the websockets api to know when a prompt execution is done\n",
    "# Once the prompt execution is done it downloads the images using the /history endpoint\n",
    "\n",
    "import websocket  # NOTE: websocket-client (https://github.com/websocket-client/websocket-client)\n",
    "import uuid\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import asyncio\n",
    "from io import BytesIO\n",
    "# 加载工作流 api 然后执行\n",
    "\n",
    "from utils.load_json import load_json\n",
    "\n",
    "# WORKFLOW_API_FILE = \"comfyui_wf_api/base_api.json\"\n",
    "WORKFLOW_API_FILE = \"comfyui_wf_api/image2image.json\"\n",
    "\n",
    "workflow = load_json(WORKFLOW_API_FILE)\n",
    "\n",
    "server_address = \"home.chrissong.top:3818\"\n",
    "client_id = str(uuid.uuid4())\n",
    "\n",
    "\n",
    "def queue_prompt(prompt, prompt_id):\n",
    "    p = {\"prompt\": prompt, \"client_id\": client_id, \"prompt_id\": prompt_id}\n",
    "    data = json.dumps(p).encode(\"utf-8\")\n",
    "    req = urllib.request.Request(\"http://{}/prompt\".format(server_address), data=data)\n",
    "    urllib.request.urlopen(req).read()\n",
    "\n",
    "\n",
    "def get_image(filename, subfolder, folder_type):\n",
    "    data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n",
    "    url_values = urllib.parse.urlencode(data)\n",
    "    with urllib.request.urlopen(\n",
    "        \"http://{}/view?{}\".format(server_address, url_values)\n",
    "    ) as response:\n",
    "        return response.read()\n",
    "\n",
    "\n",
    "def get_history(prompt_id):\n",
    "    with urllib.request.urlopen(\n",
    "        \"http://{}/history/{}\".format(server_address, prompt_id)\n",
    "    ) as response:\n",
    "        return json.loads(response.read())\n",
    "\n",
    "\n",
    "def get_images(ws, prompt):\n",
    "    prompt_id = str(uuid.uuid4())\n",
    "    queue_prompt(prompt, prompt_id)\n",
    "    output_images = {}\n",
    "    while True:\n",
    "        out = ws.recv()\n",
    "        if isinstance(out, str):\n",
    "            message = json.loads(out)\n",
    "            if message[\"type\"] == \"executing\":\n",
    "                data = message[\"data\"]\n",
    "                if data[\"node\"] is None and data[\"prompt_id\"] == prompt_id:\n",
    "                    break  # Execution is done\n",
    "        else:\n",
    "            # If you want to be able to decode the binary stream for latent previews, here is how you can do it:\n",
    "            # bytesIO = BytesIO(out[8:])\n",
    "            # preview_image = Image.open(bytesIO) # This is your preview in PIL image format, store it in a global\n",
    "            continue  # previews are binary data\n",
    "\n",
    "    history = get_history(prompt_id)[prompt_id]\n",
    "    for node_id in history[\"outputs\"]:\n",
    "        node_output = history[\"outputs\"][node_id]\n",
    "        images_output = []\n",
    "        if \"images\" in node_output:\n",
    "            for image in node_output[\"images\"]:\n",
    "                image_data = get_image(\n",
    "                    image[\"filename\"], image[\"subfolder\"], image[\"type\"]\n",
    "                )\n",
    "                images_output.append(image_data)\n",
    "        output_images[node_id] = images_output\n",
    "\n",
    "    return output_images\n",
    "\n",
    "\n",
    "prompt = workflow\n",
    "ws_url = f\"ws://{server_address}/ws\"\n",
    "print(f\"尝试连接WebSocket: {ws_url}\")\n",
    "ws = websocket.create_connection(ws_url)\n",
    "# ws.connect(\n",
    "#     ws_url,\n",
    "#     header=[f\"Origin: http://{server_address}\"],\n",
    "# )\n",
    "images = get_images(ws, prompt)\n",
    "ws.close()  # for in case this example is used in an environment where it will be repeatedly called, like in a Gradio app. otherwise, you'll randomly receive connection timeouts\n",
    "# Commented out code to display the output images:\n",
    "\n",
    "for node_id in images:\n",
    "    for image_data in images[node_id]:\n",
    "        from PIL import Image\n",
    "        import io\n",
    "\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        image.show()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
