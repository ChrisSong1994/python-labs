{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ca322a",
   "metadata": {},
   "source": [
    " # rag 全流程\n",
    "\n",
    " - 创建向量数据库\n",
    " - 加载文档并解析成文档片段\n",
    " - 转化文档片段为向量\n",
    " - 把文档片段向量插入到向量数据库中\n",
    " - 创建检索器\n",
    " - 输入问题，转化成向量，聊天模式（跟上下文的关系）\n",
    " - 获取最相似的文档，输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d485d9",
   "metadata": {},
   "source": [
    "环境初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc28dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://home.chrissong.top:11434\n"
     ]
    }
   ],
   "source": [
    "# load env\n",
    "from dotenv import load_dotenv \n",
    "import os \n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\")\n",
    "MODEL_NAME = \"llama3:8b\"  # 使用的模型名称\n",
    "EMBEDDING_MODEL = \"bge-m3\"  # 用于生成嵌入的模型\n",
    "DB_PATH = \"db\"\n",
    "DOCS_PATH = \"./docs\"\n",
    "\n",
    "print(OLLAMA_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62ad94",
   "metadata": {},
   "source": [
    "创建向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9240d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL,base_url=OLLAMA_API_URL)\n",
    "\n",
    "print(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a684d8",
   "metadata": {},
   "source": [
    "创建向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edc63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "        persist_directory= DB_PATH,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"document_collection\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729ac4d",
   "metadata": {},
   "source": [
    "文档分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95121b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader ,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "if vector_store._collection.count() == 0:\n",
    "    print(\"未发现文档，开始加载 documents 目录下的文件...\")\n",
    "    directory_loader = DirectoryLoader(DOCS_PATH, glob=\"*.pdf\", loader_cls=PDFPlumberLoader)\n",
    "    documents = directory_loader.load()\n",
    "    print(f\"加载了 {len(documents)} 个文档\")\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    # 添加到向量库\n",
    "    vector_store.add_documents(split_docs)\n",
    "    print(f\"成功加载 {len(split_docs)} 个文档片段到向量库\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05683e9c",
   "metadata": {},
   "source": [
    "创建大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4acb0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# 大语言模型\n",
    "llm = ChatOllama(model=MODEL_NAME, base_url=OLLAMA_API_URL, temperature=0.7)\n",
    "\n",
    "# 检索器\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8578d29",
   "metadata": {},
   "source": [
    "创建rag chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2137b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    请根据提供的上下文信息回答用户的问题。\n",
    "    仅使用上下文内容，信息不足时请说明无法回答。\n",
    "\n",
    "    上下文:\n",
    "    {context}\n",
    "\n",
    "    问题:\n",
    "    {input}\n",
    "\n",
    "    回答:\n",
    "    \"\"\")\n",
    "    \n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5769d",
   "metadata": {},
   "source": [
    "问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"\\n请输入问题（输入q退出）: \")\n",
    "    if question.lower() == 'q':\n",
    "        break\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "    \n",
    "    print(f\"\\n问题: {question}\")\n",
    "    print(f\"\\n回答: {response['answer']}\")\n",
    "    \n",
    "    print(\"\\n相关文档片段:\")\n",
    "    for i, doc in enumerate(response[\"context\"]):\n",
    "        print(f\"片段 {i+1}: {doc.page_content[:150]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
